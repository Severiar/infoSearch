# InfoSearch
Сервер информационного поиска на основе [Multilingual-E5-large](https://huggingface.co/intfloat/multilingual-e5-large?text=hi) и [Qdrant](https://qdrant.tech/).

## Описание данных
За основу были взяты 19 статей из википедии. Текст был очищен от ссылок,  разбит на предложения, убраны предложения короче 30 символов, каждое предложение было векторизовано с помощью [Multilingual-E5-large](https://huggingface.co/intfloat/multilingual-e5-large?text=hi), и вектор с метаданными был загружен в базу данных. К метаданным относятся сам текст предложения, заголовок статьи и ссылка на статью. Методы, с помощью которых производился парсинг википедии, находятся в файле `parsing.py`, а метод для заполнения базы данных - в `engine.py` (метод `upsert_wiki_database`). Таким образом содержимое БД выглядит так:
[Содержимое базы данных](https://drive.google.com/uc?id=1VmZGwRKsOjaXtVj1ljnqGLliVWAsCfGi)
Вам не придется разворачивать свою базу данных, т.к. я для удобства оставил URL и API-ключ уже заполненной мной базы.

## Описание интерфейса
Для взаимодействия пользователя с проектом использована библиотека FastAPI. Метод - `get_relevant_sentences_by_query` - находится в файле `api.py`, принимает на вход строку-запрос пользователя и (опционально) количество предложений-ответов. Функция возвращает топ наиболее релевантных предложений (из ранее загруженных статей) в формате JSON. Релевантность определяется косинусным расстоянием между ембеддингом запроса и ембеддингом предложения. Вместе с предложениями выводятся и их метаданные и мера близости. Одно предложение-ответ с метаданными имеет следующий JSON-формат:
```
{
    "id": 574,
    "version": 2617,
    "score": 0.8532586,
    "payload": {
        "text": "«Южный Парк» первоначально задумывался как пародийный сериал.",
        "title": "Южный Парк",
        "url": "https://ru.wikipedia.org/wiki/Южный_Парк"
    },
    "vector": null,
    "shard_key": null
}
```

## Инструкция по использованию
Предполагается, что у Вас уже установлен Python и пакеты `pip`, `pipenv`.

Чтобы локально запустить сервер на Вашем компьютере:

1. Склонируйте проект командой `git clone git@github.com:Severiar/infoSearch.git`
2. Перейдите в корневой каталог проекта командой: `cd infoSearch`
3. Создайте виртуальную среду проекта командой: `pipenv install`
4. Перейдите в созданную виртуальную среду командой: `pipenv shell`
5. Запустите FastAPI-сервер командой `python api.py`
6. Откройте в браузере страницу по адресу http://localhost:8000/docs. Перед Вами должна открыться страница с единственным методом: [FastAPI страница](https://drive.google.com/uc?id=1z1ZM9YS9huE-4KlE1T7fZposRLLEMhqL)
Раскройте панель метода, нажмите на кнопку `Try it out` справа, введите запрос в поле query и нажмите `Execute`. В поле **Response Body** Вы увидите результат - топ самых релевантных Вашему запросу предложений с метаданными (из имеющихся в БД) в формате JSON:
[Пример запроса и ответа](https://drive.google.com/uc?id=1XsvRjix2hvNBjBbPa-To4NLdjAIfsFHB)

### Дополнительные файлы (задание 5)
В файле `usage_example.py` приведён пример кода, который посылает запросы к поднятому серверу. В нем последовательно запрашиваются топ-10 релевантных предложений для каждого из 5 запросов (выданных в ТЗ к проекту). И результат записан в файле `usage_result_example.py`. 
